###
services:
  anything:
    networks:
      - openland
    labels:
      - traefik.enable=true
      - traefik.docker.network=openland
      - traefik.http.routers.anything-router.rule=Host(`anything.openaide.localhost`)
      - traefik.http.routers.anything-router.entrypoints=web
      - traefik.http.services.anything.loadbalancer.server.port=3001
      - custom.traefik.group=openaide

  # # https://github.com/ollama/ollama/blob/main/docs/docker.md
  # ollama:
  #   image: ollama/ollama
  #   # container_name: ollama
  #   networks:
  #     - openland
  #   # ports:
  #   #   - "11434:11434"
  #   volumes:
  #     - ollama:/root/.ollama
  #   restart: unless-stopped

  # https://github.com/mudler/LocalAI?tab=readme-ov-file
  localai:
    image: localai/localai:latest-aio-cpu
    platform: linux/amd64
    # container_name: localai
    networks:
      - openland
    # ports:
    #   - "8080:8080"
    restart: unless-stopped

##
volumes:
  ollama:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: local_ollama.bak
  anythingllm_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: local_llm_storage.bak

##
networks:
  openland:
    external: true

###